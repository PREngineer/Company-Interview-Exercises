# DevOps Practical Exercise - AWS or Azure

## Primary Task

Create a very simple REST API that when its endpoint is called, it returns one object from S3 or Azure Blob Storage that is a JSON file. For example GET `/api/foo` returns contents of JSON file with something like `{ "greeting": "I am the Foo" }`. But really do whatever you want there as long as it accesses S3 or Azure Blob Storage to get the content. You can create this in any development language with any framework, or you can use a sample app from somewhere online (note your source if you do so). If you need help with this, let us know. Keep this simple, its a 10-20 line app at most.

- Use infrastructure as code (i.e. Terraform, Pulumi, or other)
- You may use containers or instances for the application backend. If you would like to propose using an alternative approach instead of containers or instances for the backend, please discuss this with the team beforehand and justify your case. Otherwise, please follow the instructions to use containers or instances.
- Deploy the backend to a private network (VPC or VNet)
- Create your own S3 bucket or Azure Blob Storage for the JSON files
- Expose the service through a termination on publicly accessible network

Bonus task (optional)

- Make the service autoscale

Please commit all work to _THIS_ repository, using normal practices for working in a team. If you use pull requests, please merge them yourself and we will still be able to see the history.

## General Note

Beyond the functional requirements, your submission will be judged primarily based on adherence to best practices, so use the same professional-quality code and commitment to automation that you would deliver on a real client project. If you need to take any shortcuts to fit the work in the time allowed, please document these as future work items to demonstrate that you made an explicit tactical decision to deviate from your normal best practices.

## FAQ

- "Publicly accessible network" means that the application should be accessible using a common web browser and the URL that was generated by the deployment process.
- In the reviewing process, we will deploy the resources using the instructions provided. You can delete your resources at your own discretion.

----

## How to manually create the Resource Group, Azure Storage Account, and Container

In order to access the "data" that the API will return, I need to create a Storage Account.  It will have a container with permissions set to publicly accessible blobs.  Why?  Because the requirements specify that the application should be very tiny.  If I were to add access restrictions, I would have to include a lot of additional code to just access the blob storage.  The greetings.json file will be uploaded to the container and I will save the blob URL for access by the API.

### Storage Account

1. Log into the Azure Portal
2. Search for Storage Accounts and click it
3. Click the "+ Create" button
4. Select Subscription
5. Create new Resource Group: "TheoremOne-Sample"
6. Provide an Account Name: "theo1sample"
7. Select Region: "East US 2"
8. Select Performance: "Standard"
9. Select Redundancy: "Locally-redundant storage (LRS)"
10. Click the "Review" button.
11. Click the "Create" button.
12. Wait for Deployment to complete.
13. Click the "Go to resource" button.

## Storage Container

1. On the left side of the Storage Account, click the "Containers" link.
2. Click the "+ Container" button on top.
3. Name it: "greetings"
4. Click the "Create" button.

## Uploading the JSON file

1. Click on the "greetings" container.
2. Click on the "Upload" button.
3. Click on the "Browse for files" link.
4. Look for the "greetings.json" file.
5. Click the "upload" button.

## Granting public read access to the Storage Account blobs

1. Go back to the Storage Account level.
2. Click on "Configuration" on the left side.
3. Click the "Enabled" radio button on the "Allow Blob anonymous access" option.
4. Click the "Save" button.
5. Click on "Containers" on the left side to view our containers and select the container that was created.
6. Click the "Change access level" button on top.
7. Change "Anonymous access level" to Blob (anonymous read access for blobs only).
8. Press the "OK" button.
9. Click on the blob (file) that we uploaded and copy the URL in the Overview, should be something like this:
https://theo1sample.blob.core.windows.net/greetings/greetings.json

It should be publicly readable now.

----

## How to create the Resource Group, Storage Account, and Container using the Azure PowerShell Module

The ARM templates included were generated by the Azure Template generator.  This is known to be a little 'quirky.'  I have manually deployed these instead, but I include this for reference.

### Installing the Azure PowerShell Module

1. Open PowerShell as Administrator
2. Run the following commandlets:

  ``Set-ExecutionPolicy -ExecutionPolicy Unrestricted``

  ``Install-Module -Name Az -AllowClobber -Scope CurrentUser``

3. Validate that you can connect to Azure now:

  ``Connect-AzAccount``

If using MFA:
  
  ``Connect-AzAccount -TenantId <tenant id>``
 
4. Enter the Azure Credentials in the pop up window to log in

### Creating the Resource Group

1. Open PowerShell
2. Connect to Azure AD:

	``Connect-AzAccount -TenantId <id>``

4. Create the Resource Group by running the following cmdlet:

	``New-AzResourceGroup -name TheoremOne-Sample -Location "East US 2"``

### Creating the Storage Account and Container

1. Navigate to the directory containing the ARM templates within PowerShell.
2. Run the following cmdlet to create the resources:

  ``New-AzResourceGroupDeployment -ResourceGroupName TheoremOne-Sample -TemplateFile StorageAndContainer.json``

3. Import the greetings.json file into the Azure blob container by navigating into the container and uploading the file within the Azure Portal.

----

## How to create the Azure Kubernetes Service cluster

AKS has a minimum set of requirements to spin up a Kubernetes cluster.  It is no longer doable with low end VM SKUs.  This means that it will spin, at minimum a 4/16 VM per node or it will error out.

1. Log into the Azure Portal
2. Search for Kubernetes Service
3. Click on it
4. Click on the "+ Create" button" and pick "Create a Kubernetes cluster"
5. Pick the Azure Subscription
6. Pick the Resource Group already created
7. Under Cluster preset configuration, pick: Dev/Test
8. Name: theoremcluster
9. Region: US East 2
10. Zones: 1,2,3
11. Pricing tier: Free
12. Kubernetes version: 1.26.6
13. Automatic upgrade: Enabled with patch
14. Node size: Leave as it is
15. Scale Method: Autoscale
16. Node count: 1-2
17. Click "Review + Create"
18. Click the "Create" button

----

## PHP Application

Given the requirements of this exercise to be a very tiny application, I am using PHP to return a JSON encoded response to only the specific valid URI /api/foo.

The PHP application will validate the URI provided, if it doesn't match that, it will return a 404.  If it does, it will grab the contents of the blob in Azure and return it.

I am assuming that the blob is a properly formed JSON file and returning it as it is.

I am going to use Apache2 as the web server for the application.  I have added an .htaccess file that will redirect all requests to the /api/index.php application.

Validated using WAMP Server that:

1. Requests to http://localhost/api/foo return the proper response.
2. Any other request will return a 404.  e.g. http://localhost | http://localhost/api | http://localhost/api/bar

The contents of the PHP app are located in the /App directory of the repository.

NOTE: When deploying again, replace the baked in Storage Blob URL with yours.

----

## Dockerization

I have created a Dockerfile to use with Docker Desktop to build the docker container image for this application.

To use it:

1. Using Command Prompt or PowerShell, cd into the directory with the file
2. Build using the command:

  ``docker build -t prengineer/theorem1 . -f Dockerfile``

3. Run with Docker to validate that it works, with the following command:

  ``docker run -it --rm -p 80:80 prengineer/theorem1``

4. Push to DockerHub after validation

NOTE: I am using my personal dockerhub account for this.  When deploying, you will have to specify your own registry and edit the deployment file also.

----

## Kubernetes Deployment Definition

I have created a TheoremOne-Deployment.yaml file that will be used to deploy the application to the AKS cluster.

Main takeaways are:

1. I have defined a production namespace for this application
2. I have specified that the deployment should use pods to 90% of CPU resources.
3. Pods are defined with a constrained CPU and RAM capacity as this application is very small.
4. The deployment establishes a Horizontal Auto Scaling policy with a minimum of 1 pod and a maximum of 10 pods.
5. The application will be exposed using port 80 (HTTP).
6. For my AKS cluster, the master node seems to be in the internal IP 10.0.0.1.  I am pointing the Service to that IP as its listening endpoint.
7. I will be testing the application using its public IP, assigned by Microsoft.

----

## Deploying to Azure Kubernetes Service

1. Open the Cloud Shell in the Azure Portal
2. Type the following command to connect:
  
  ``az aks get-credentials --resource-group TheoremOne-Sample --name theoremcluster``

3. Validate that it connected by running the following command:
	
  ``kubectl get nodes``

4a. Copy the deployment file from source code repository.  Given that the repo is not public, you would need a token to grab the contents of the deployment file.
    
  ``curl https://raw.githubusercontent.com/TheoremOne-Assessments/devops-d1bbc126-ec6e-4036-ba08-e9ce811732d3-devops/main/TheoremOne-Deployment.yaml?token=TOKEN_GOES_HERE > TheoremOne-Deployment.yaml``

4b. Otherwise, copy and paste the content inside the Cloud Shell:
    
  ``nano TheoremOne-Deployment.yaml``
    
    paste here

  ``CTRL + X``

  ``Y + Enter``

5. Apply the deployment to the cluster

  ``kubectl apply -f TheoremOne-Deployment.yaml``

6. Watch the deployment until it completes

  ``watch kubectl get all -n production``

7. Copy the External IP of the service created:

e.g. 20.96.212.36

----

## Testing the application

1. Open your browser and navigate to the external IP of the cluster.

2. For these cases, you should have the following results:

Successs (200 and data):

``http://20.96.212.36/api/foo``

Failure (404):

  ``http://20.96.212.36/api/bar``

  ``http://20.96.212.36/api/``

  ``http://20.96.212.36``

----

## Closing Considerations

There are many things that could be improved but these are the first that come to mind.

## Assumptions

Based on the description of the problem, I assumed that the API would only return the JSON file as a reponse to the request URI /api/foo.  For any other request type, it would return a 404.  The application code is also assuming that the contents of the greetings.json file are properly JSON formatted.

## Permissions

I made the Azure Blob public so that the PHP app wouldn't have to get unnecessarily larger.  It would have taken a lot more lines of code and adding libraries to access it with restrictions.  Depending on the type of data being stored, locking the file down with permissions would be the usual.

### Regarding Infrastructure

I did not assign a static public IP to the cluster in this exercise.  It would have been beneficial to do so.  It provides the certainty of always having the same public IP and that could be baked into the process.

Additionally if, instead of using the AKS Service, I had deployed VMs in an auto-scaling set; I would have more control over the sizing of the resources deployed to the cloud.  The drawback is including additional maintenance of the VMs and clusters.

### Parametrization

Configuration settings, etc., were not passed as parameters.  For example, the PHP application has the URL of the Azure Storage Blob baked into it.  It could have been passed as an environment variable to the entrypoint script to populate.

### CI/CD

For the purposes of a real application, I would have implemented a DevOps Pipeline in either Jenkins or Azure DevOps.

This pipeline would be tied to the GitHub repository using Web Hooks, to trigger a build upon commits.

Given that the application I provided is written in PHP, I would bake in steps like performing PHPUnit tests, PHPLint, etc.

Upon successful tests, the application could be packaged into a release zip file and added to the GitHub releases or some other artifact repository.  The application can be containerized automatically using Kaniko and pushed to a Container Registry.

Additionally, a series of deployment steps can be built into the pipeline to deploy to Test/Stage/Prod either automatically or after approvals.

## Closing Remarks

Thanks for your consideration and the opportunity to participate in this exercise.  I hope that you have a great rest of your day.

- Jorge Pabón Sept/6/2023